{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "First pass at analysing the output of blasting AML RNA-Seq data against the three tryptase sequences from Jonathon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(folder):\n",
    "    \n",
    "    return glob.glob('{folder}/*sorted.bam'.format(folder=folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_control_results = get_files('../control_results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_file_names = [x.split('/')[len(x.split('/'))-1] for x in list_of_control_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control = pd.DataFrame(index=control_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control['file_location'] = list_of_control_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control['source'] = 'control'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_location</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file_location, source]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_control.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_location    0\n",
       "source           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_read_count(df):\n",
    "\n",
    "    return int(pysam.view(\"-c\", df['file_location']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set a frame with no defined index and a value that cannot be converted to a Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/panfs/pan1.be-md.ncbi.nlm.nih.gov/product_manager_research_projects/joseph/tryptase/tryptase_project/myvenv/lib/python3.6/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36m_asarray_tuplesafe\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (0,2) into shape (0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/panfs/pan1.be-md.ncbi.nlm.nih.gov/product_manager_research_projects/joseph/tryptase/tryptase_project/myvenv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ensure_valid_index\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   2563\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2564\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2565\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/panfs/pan1.be-md.ncbi.nlm.nih.gov/product_manager_research_projects/joseph/tryptase/tryptase_project/myvenv/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    263\u001b[0m                 data = _sanitize_array(data, index, dtype, copy,\n\u001b[0;32m--> 264\u001b[0;31m                                        raise_cast_failure=True)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/panfs/pan1.be-md.ncbi.nlm.nih.gov/product_manager_research_projects/joseph/tryptase/tryptase_project/myvenv/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m   3276\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3277\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/panfs/pan1.be-md.ncbi.nlm.nih.gov/product_manager_research_projects/joseph/tryptase/tryptase_project/myvenv/lib/python3.6/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36m_asarray_tuplesafe\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;31m# we have a list-of-list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot copy sequence with size 2 to array axis with dimension 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-186846e15562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alignment_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_read_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/panfs/pan1.be-md.ncbi.nlm.nih.gov/product_manager_research_projects/joseph/tryptase/tryptase_project/myvenv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2518\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2519\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/panfs/pan1.be-md.ncbi.nlm.nih.gov/product_manager_research_projects/joseph/tryptase/tryptase_project/myvenv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2582\u001b[0m         \"\"\"\n\u001b[1;32m   2583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2585\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2586\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/panfs/pan1.be-md.ncbi.nlm.nih.gov/product_manager_research_projects/joseph/tryptase/tryptase_project/myvenv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ensure_valid_index\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   2564\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2566\u001b[0;31m                 raise ValueError('Cannot set a frame with no defined index '\n\u001b[0m\u001b[1;32m   2567\u001b[0m                                  \u001b[0;34m'and a value that cannot be converted to a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2568\u001b[0m                                  'Series')\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set a frame with no defined index and a value that cannot be converted to a Series"
     ]
    }
   ],
   "source": [
    "df['alignment_count'] = df.apply(get_read_count, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript_count(df, transcript_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return the count of the transcript i.e how many of each of the three are in there.\n",
    "    Note - Does not look at the quality of the alignment.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sam_file_location = df['file_location']\n",
    "    \n",
    "    samfile = pysam.AlignmentFile(sam_file_location, \"rb\")\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for read in samfile:\n",
    "        \n",
    "        if read is not None and read.reference_name == transcript_name:\n",
    "            \n",
    "            count = count + 1\n",
    "            \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alpha_wt_count'] = df.apply(get_transcript_count, axis=1, args=['Alpha_GEX_64k_HEX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alpha_dup_count'] = df.apply(get_transcript_count, axis=1, args=['Alpha_GEX_79k_dup_FAM'])\n",
    "df['beta_count'] = df.apply(get_transcript_count, axis=1, args=['BETA_new_GEX_FAM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zero_edit_distance_count(df, transcript_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    For a goven transcript e.g. Alpha_GEX_64k_HEX get how many of the matches have an NM tag of zero\n",
    "    i.e. the match was exact.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sam_file_location = df['file_location']\n",
    "    \n",
    "    samfile = pysam.AlignmentFile(sam_file_location, \"rb\")\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for read in samfile:\n",
    "        \n",
    "        if read is not None and read.reference_name == transcript_name:\n",
    "            \n",
    "            edit_distance = read.get_tag('NM')\n",
    "            \n",
    "            if edit_distance == 0:\n",
    "                \n",
    "                count = count + 1\n",
    "            \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alpha_wt_zero_edit_count'] = df.apply(get_zero_edit_distance_count, axis=1, args=['Alpha_GEX_64k_HEX'])\n",
    "df['alpha_dup_zero_edit_count'] = df.apply(get_zero_edit_distance_count, axis=1, args=['Alpha_GEX_79k_dup_FAM'])\n",
    "df['beta_zero_edit_count'] = df.apply(get_zero_edit_distance_count, axis=1, args=['BETA_new_GEX_FAM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript_read_count_filtered(df, transcript_name, start, end):\n",
    "    \n",
    "    \"\"\"\n",
    "    Count hits which cover the bit of the reference we are interested in\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sam_file_location = df['file_location']\n",
    "    \n",
    "    samfile = pysam.AlignmentFile(sam_file_location, \"rb\")\n",
    "    \n",
    "    iter = samfile.fetch(transcript_name, start, end)\n",
    "    \n",
    "    count =0\n",
    "    \n",
    "    for read in iter:\n",
    "        \n",
    "        if read.reference_start <=start and read.reference_end >= end:\n",
    "            \n",
    "            count = count +1\n",
    "            \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alpha_read_covers_snps_count'] = df.apply(get_transcript_read_count_filtered,\n",
    "                                              axis=1,\n",
    "                                              args=['Alpha_GEX_64k_HEX', 25,45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alpha_dup_read_covers_snps_count'] = df.apply(get_transcript_read_count_filtered,\n",
    "                                              axis=1,\n",
    "                                              args=['Alpha_GEX_79k_dup_FAM', 25,45])\n",
    "\n",
    "df['beta_read_covers_snps_count'] = df.apply(get_transcript_read_count_filtered,\n",
    "                                              axis=1,\n",
    "                                              args=['BETA_new_GEX_FAM', 25,45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='alpha_dup_read_covers_snps_count', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript_read_count_filtered_exact(df, transcript_name, start, end):\n",
    "    \n",
    "    \"\"\"\n",
    "    Count hits which cover the bit of the reference we are interested in and which are exact.\n",
    "    \n",
    "    That is do they cross position 0 - 44 of the transcript ( given by transcipt_name) and \\\n",
    "    have an edit distance from the reference of 0. \n",
    "    \n",
    "    Reads which cross this location will cross all four SNPs needed to tell the 3 transcripts apart.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sam_file_location = df['file_location']\n",
    "    \n",
    "    samfile = pysam.AlignmentFile(sam_file_location, \"rb\")\n",
    "    \n",
    "    iter = samfile.fetch(transcript_name, start, end)\n",
    "    \n",
    "    count =0\n",
    "    \n",
    "    for read in iter:\n",
    "        \n",
    "        if read.reference_start <=start and read.reference_end >=end:\n",
    "            \n",
    "            edit_distance = read.get_tag('NM')\n",
    "            \n",
    "            if edit_distance == 0:\n",
    "                \n",
    "                count = count + 1\n",
    "                \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alpha_read_covers_snps_count_exact'] = df.apply(get_transcript_read_count_filtered_exact,\n",
    "                                              axis=1,\n",
    "                                              args=['Alpha_GEX_64k_HEX', 25,45])\n",
    "\n",
    "df['alpha_dup_read_covers_snps_count_exact'] = df.apply(get_transcript_read_count_filtered_exact,\n",
    "                                              axis=1,\n",
    "                                              args=['Alpha_GEX_79k_dup_FAM', 25,45])\n",
    "\n",
    "df['beta_read_covers_snps_count_exact'] = df.apply(get_transcript_read_count_filtered_exact,\n",
    "                                              axis=1,\n",
    "                                              args=['BETA_new_GEX_FAM', 25,45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check to see if any such reads exist\n",
    "\n",
    "#df.sort_values(by='alpha_dup_read_covers_snps_count_exact', ascending=False).head()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check\n",
    "\n",
    "Print out some of the reads. I then did a manual BLAST and alignment to check the code was working as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript_read_count_filtered_exact_print(sam_file_location, transcript_name, start, end):\n",
    "    \n",
    "    \"\"\"\n",
    "    Same as get_transcript_read_count_filtered_exact() except we just print out the reads instead of \\\n",
    "    counting them.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    samfile = pysam.AlignmentFile(sam_file_location, \"rb\")\n",
    "    \n",
    "    iter = samfile.fetch(transcript_name, start, end)\n",
    "    \n",
    "    for read in iter:\n",
    "        \n",
    "        if read.reference_start <=start and read.reference_end >= end:\n",
    "            \n",
    "            edit_distance = read.get_tag('NM')\n",
    "            \n",
    "            if edit_distance == 0:\n",
    "                \n",
    "                print (read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick a random bam file with some read alignments in this area\n",
    "\n",
    "get_transcript_read_count_filtered_exact_print('../aml_results/aml_aabspliced_SRR5626188.sam.sorted.bam',\n",
    "                                               'Alpha_GEX_64k_HEX',\n",
    "                                               25,\n",
    "                                               45 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.control.3snps.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
